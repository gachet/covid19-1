{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pip install googletrans\n",
    "from googletrans import Translator\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re, string\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import spanish twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import csv twitts in Spanish\n",
    "es_twitts=pd.read_csv('data/clean/es_twitts.csv')\n",
    "\n",
    "## Filtering by only MX\n",
    "#es_twitts.query(\"country_code=='MX'\").count()\n",
    "es_twitts=es_twitts.query(\"country_code=='MX'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_twitts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitts translation from Spanish to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "es_twitts['text_english'] = es_twitts['text'].apply(translator.translate, src='es', dest='en').apply(getattr, args=('text',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export csv twitts traslated in English\n",
    "#es_twitts.to_csv (r'C:\\input\\english_twitts.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import csv twitts in Spanish\n",
    "es_twitts=pd.read_csv('C:\\\\input\\\\english_twitts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Noise from the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('https?:\\/\\/.*[\\r\\n]*','', token)\n",
    "        token = re.sub('http?:\\/\\/.*[\\r\\n]*','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sentiment Model Trained and Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load:\n",
    "f = open('sentiment_classifier.pickle', 'rb')\n",
    "classifier = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model to classify twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in es_twitts.iterrows():\n",
    "    #print(index)\n",
    "    #print(row['created_at'],row['text'],row['text_english'])\n",
    "        \n",
    "    custom_tokens = remove_noise(word_tokenize(row['text_english']))\n",
    "    \n",
    "    es_twitts.at[index,'classified']=classifier.classify(dict([token, True] for token in custom_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export csv twitts traslated in English\n",
    "#es_twitts.to_csv (r'C:\\input\\classified_twitts.csv', index = None, header=True)\n",
    "\n",
    "## Import csv twitts traslated in English\n",
    "es_twitts=pd.read_csv('C:\\\\input\\\\classified_twitts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporing the necessary columns to plot\n",
    "es_twitts_plot = pd.DataFrame()\n",
    "\n",
    "es_twitts_plot[\"created_at\"]=es_twitts.created_at\n",
    "#es_twitts_plot[\"spa\"]=es_twitts.text\n",
    "#es_twitts_plot[\"eng\"]=es_twitts.text_english\n",
    "\n",
    "es_twitts_plot.loc[es_twitts['classified'].str.contains('Positive'), 'pos'] = 'yes'\n",
    "es_twitts_plot.loc[es_twitts['classified'].str.contains('Negative'), 'neg'] = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_twitts_plot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Coverting all date values in proper Datetime format\n",
    "for i in range(len(es_twitts_plot.created_at)):\n",
    "     es_twitts_plot.created_at[i] = dt.datetime.strptime(es_twitts_plot.created_at[i],'%Y-%m-%dT%H:%M:%SZ').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to get positive/negavite counts per day\n",
    "es_twitts_plot['count_pos']  = es_twitts_plot.groupby('created_at')['pos'].transform('count')\n",
    "es_twitts_plot['count_neg'] = es_twitts_plot.groupby('created_at')['neg'].transform('count')\n",
    "\n",
    "es_twitts_plot.drop(['pos', 'neg'],axis=1,inplace=True)\n",
    "es_twitts_plot.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_twitts_plot.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting twitts Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=es_twitts_plot['created_at'], y=es_twitts_plot['count_pos'], name=\"Positive\",\n",
    "                         line_color='deepskyblue'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=es_twitts_plot['created_at'], y=es_twitts_plot['count_neg'], name=\"Negative\",\n",
    "                         line_color='dimgray'))\n",
    "\n",
    "fig.update_layout(title_text='MX Twitts Positive/Negative Per Day',\n",
    "                  xaxis_rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud By Twitts Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_twitts=es_twitts.query('classified==\"Positive\"')\n",
    "neg_twitts=es_twitts.query('classified==\"Negative\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = df.description[0]\n",
    "text = (\" \").join(pos_twitts.text.tolist())\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = df.description[0]\n",
    "text = (\" \").join(neg_twitts.text.tolist())\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
